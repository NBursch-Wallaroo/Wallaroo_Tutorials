{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6acc34",
   "metadata": {},
   "source": [
    "# How to Convert Keras to ONNX\n",
    "\n",
    "The following tutorial is a brief example of how to convert a [Keras](https://keras.io/) or Tensor ML model to [ONNX](https://onnx.ai/ ).  This allows organizations that have trained Keras or Tensor models to convert them and use them with Wallaroo.\n",
    "\n",
    "This tutorial assumes that you have a Wallaroo instance and are running this Notebook from the Wallaroo Jupyter Hub service.  This sample code is made to work with the Wallaroo IMDB demo.  The models converted from this procedure can directly be used in that demonstration.\n",
    "\n",
    "* **IMPORTANT NOTE**:  As of this time, this tutorial does not work in a Wallaroo instance.  The instructions have been geared towards converting these models in a separate Python environment.  Note that there may be warnings displayed based on whether you have a GPU installed in the target machine - these can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22978935",
   "metadata": {},
   "source": [
    "This tutorial provides the following:\n",
    "\n",
    "* `embedder`: akes pre-tokenized text documents (model input: 100 integers/datum; output 800 numbers/datum) and creates an embedding from them.  It has the input signature name of `input`.\n",
    "* `sentiment_model`: The second model classifies the resulting embeddings from 0 to 1, which 0 being an unfavorable review, 1 being a favorable review.  This has 800 inputs.  It has the input signature name of `embeddings`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03988a4d",
   "metadata": {},
   "source": [
    "The following libraries need to be installed in your Python environment:\n",
    "    \n",
    "* onnxconverter-common\n",
    "* numpy\n",
    "* keras\n",
    "* tensorflow\n",
    "* onnxruntime\n",
    "* tf2onnx\n",
    "* onnx\n",
    "\n",
    "These can be installed through either `pip` or `conda`, depending on your Python environment.  For example:\n",
    "\n",
    "```\n",
    "pip install numpy keras tensorflow onnxruntime tf2onnx onnx onnxconverter-common\n",
    "```\n",
    "\n",
    "Once installed, they can be imported into your Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793b8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 18:53:25.410680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-22 18:53:25.410716: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import onnxruntime\n",
    "import tf2onnx\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffc02c",
   "metadata": {},
   "source": [
    "## Load the Models\n",
    "\n",
    "The first step is to load the models via the `keras.models.load_model` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22497016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 18:53:26.989602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-22 18:53:26.989644: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-22 18:53:26.989666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wallaroo): /proc/driver/nvidia/version does not exist\n",
      "2022-04-22 18:53:26.989861: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "embedder = keras.models.load_model('embedder')\n",
    "sentiment = keras.models.load_model('sentiment_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf28f5",
   "metadata": {},
   "source": [
    "## Retrieve the Opset\n",
    "\n",
    "The following code will retrieve the correct Onnx Opset Version that will be used for the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8389450d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out the correct opset\n",
    "\n",
    "from onnx.defs import onnx_opset_version\n",
    "from onnxconverter_common.onnx_ex import DEFAULT_OPSET_NUMBER\n",
    "TARGET_OPSET = min(DEFAULT_OPSET_NUMBER, onnx_opset_version())\n",
    "TARGET_OPSET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9cb07",
   "metadata": {},
   "source": [
    "## Convert the Model\n",
    "\n",
    "The model conversion uses the method `tf2onnx.convert.from_keras(model, insert_signature, opset)` which takes the following arguments as detailed in the [tensorflow-onnx](https://github.com/onnx/tensorflow-onnx):\n",
    "\n",
    "* `model`: the tf.keras model we want to convert\n",
    "* `input_signature`: a tf.TensorSpec or a numpy array defining the shape/dtype of the input\n",
    "* `opset`: the opset to be used for the ONNX model, default is the latest\n",
    "\n",
    "In the following example, the `input_signature` is set first for the `embedder` conversion, then for the `sentiment_model` conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a44912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jhummel/projects/keras-to-onnx/lib/python3.8/site-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 18:53:27.475655: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-22 18:53:27.475803: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-22 18:53:27.514245: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.007ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-04-22 18:53:27.533604: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-22 18:53:27.533714: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-22 18:53:27.536251: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  constant_folding: Graph size after: 11 nodes (0), 11 edges (0), time = 0.855ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "  constant_folding: Graph size after: 11 nodes (0), 11 edges (0), time = 0.256ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_signature = [tf.TensorSpec([None, 100], tf.float32, name='input')]\n",
    "\n",
    "onnx_model_embedded, _  = tf2onnx.convert.from_keras(embedder, input_signature, opset=TARGET_OPSET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5fff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 18:53:27.594728: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-22 18:53:27.594816: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-22 18:53:27.595529: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n",
      "2022-04-22 18:53:27.609848: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-04-22 18:53:27.609944: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-22 18:53:27.611573: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  constant_folding: Graph size after: 8 nodes (-2), 9 edges (-2), time = 0.498ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "  constant_folding: Graph size after: 8 nodes (0), 9 edges (0), time = 0.2ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_signature = [tf.TensorSpec([None, 800], tf.float32, name='embeddings')]\n",
    "onnx_model_sentiment, _  = tf2onnx.convert.from_keras(sentiment, input_signature, opset=TARGET_OPSET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2d057",
   "metadata": {},
   "source": [
    "## Save the Models\n",
    "\n",
    "Once converted, the models can be saved with the `onnx.save(model, filename)` method with takes the following arguments:\n",
    "\n",
    "* model: The model to save.\n",
    "* filename:  The file name to save the model to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d45b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(onnx_model_embedded, 'embedder.onnx')\n",
    "\n",
    "onnx.save(onnx_model_sentiment, 'sentiment_model.onnx')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
