{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Linear Regression Model Notebook for the Wallaroo Platform\n",
    "This model will predict whether or not the room is occupied based on the data from sensors to detect people in a room.\n",
    "\n",
    "## A Comprehensive Tutorial for:\n",
    "\n",
    "1. Building a Linear Regression Model\n",
    "2. Deploying the Model into Wallaroo\n",
    "3. Using Wallaroo's Monitoring Capabilities to Analyze the Model.\n",
    "\n",
    "### The data was used from GC Wkshps\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Room+Occupancy+Estimation\n",
    "\n",
    "Adarsh Pal Singh, Vivek Jain, Sachin Chaudhari, Frank Alexander Kraemer, Stefan Werner and Vishal Garg, \"Machine Learning-Based Occupancy Estimation Using Multivariate Sensor Nodes,\" in 2018 IEEE Globecom Workshops (GC Wkshps), 2018. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [Building a Simple Linear Regression Model](#build)\n",
    "    * [Sensors used to collect data](#sensor)\n",
    "    * [Importing the Necessary Python Libraries](#pylib)\n",
    "    * [Importing the Data Set using Pandas](#data)\n",
    "    * [Pulling our Independent (x) and Dependent (y) Variables from the DataFrame](#variable)\n",
    "    * [Splitting the Data Set into Testing and Training Subsets](#test_train)\n",
    "    * [Creating the Linear Regression Model using Sklearn and Fitting our Training Data to the Model](#make_model)\n",
    "    * [Predicting the Room Occupancy from our Independent Variable Test Set](#predict)\n",
    "    * [Finding the Metrics to Analyze the Prediction](#metrics)\n",
    "    * [Plotting the Linear Regression](#plot)\n",
    "* [Deploying the Model into Wallaroo](#wallaroo)\n",
    "    * [Converting the Sklearn Model into Onnx for use on the Wallaroo Platform](#onnx)\n",
    "    * [Implementing into Wallaroo](#implement)\n",
    "    * [Creating a Pipeline and Uploading the Model](#pipeline)\n",
    "    * [Adding Validation to the model](#validation)\n",
    "    * [Adding Post-Process](#postprocess)\n",
    "* [Using Wallaroo's Monitoring Capabilities to Analyze the Model.](#analyze)\n",
    "    * [Deploying the Model](#deploy)\n",
    "    * [Checking the deployment](#check)\n",
    "    * [Making an Inference](#inference)\n",
    "    * [Extracting data](#extract)\n",
    "    * [Getting Single Datums](#datums)\n",
    "    * [Making the inference](#makeinference)\n",
    "    * [Interpreting the Inference](#interpret)\n",
    "    * [Format Results](#results)\n",
    "    * [Undeploy the pipeline](#undeploy)\n",
    "    * [Logs](#logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### Building a Simple Linear Regression Model <a class=\"anchor\" id=\"build\"></a>\n",
    "\n",
    "This model will be built from a data set of sensor values and the occupancy of the room the sensors are in.\n",
    "\n",
    "The goal is to use the sensor data to predict the room occupancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensors used to collect data <a class=\"anchor\" id=\"sensor\"></a>\n",
    "- `Temperature` - Four sensors that measured temperature in the room\n",
    "- `Light` -  Four sensors that measured light in the room\n",
    "- `Sound` - Four sensors that measured sounds in the room\n",
    "- `CO2` - Two sensors that measured carbon dioxide in the room\n",
    "- `PIR` - Two sensors that measured motion in the room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Necessary Python Libraries <a class=\"anchor\" id=\"pylib\"></a>\n",
    "- `matplotlib` - for data visualization\n",
    "- `numpy` - for data tuning\n",
    "- `sklearn` - for creating the linear regression model and metrics of the model\n",
    "- `pandas` - for csv importing\n",
    "- `onnx` - for converting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Source: Us\n",
    "\n",
    "# Needed for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Needed for data tuning\n",
    "import numpy as np\n",
    "\n",
    "# Needed for creating the linear regression model\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Needed for metrics of the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Needed for csv importing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data Set using Pandas <a class=\"anchor\" id=\"data\"></a>\n",
    "The first step creating a linear regression model is read in the dataset using the pandas library  \n",
    "The `read_csv` method is responsible for reading in the data and `head()` method acesses the first few rows in the data  \n",
    "When picking a variable from the data we'll use `.corr()` to find which variable has the best correlation in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>S1_Temp</th>\n",
       "      <th>S2_Temp</th>\n",
       "      <th>S3_Temp</th>\n",
       "      <th>S4_Temp</th>\n",
       "      <th>S1_Light</th>\n",
       "      <th>S2_Light</th>\n",
       "      <th>S3_Light</th>\n",
       "      <th>S4_Light</th>\n",
       "      <th>S1_Sound</th>\n",
       "      <th>S2_Sound</th>\n",
       "      <th>S3_Sound</th>\n",
       "      <th>S4_Sound</th>\n",
       "      <th>S5_CO2</th>\n",
       "      <th>S5_CO2_Slope</th>\n",
       "      <th>S6_PIR</th>\n",
       "      <th>S7_PIR</th>\n",
       "      <th>Room_Occupancy_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:49:41</td>\n",
       "      <td>24.94</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.38</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:50:12</td>\n",
       "      <td>24.94</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:50:42</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.50</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:51:13</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>390</td>\n",
       "      <td>0.388462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017/12/22</td>\n",
       "      <td>10:51:44</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.56</td>\n",
       "      <td>25.44</td>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>390</td>\n",
       "      <td>0.253846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  S1_Temp  S2_Temp  S3_Temp  S4_Temp  S1_Light  \\\n",
       "0  2017/12/22  10:49:41    24.94    24.75    24.56    25.38       121   \n",
       "1  2017/12/22  10:50:12    24.94    24.75    24.56    25.44       121   \n",
       "2  2017/12/22  10:50:42    25.00    24.75    24.50    25.44       121   \n",
       "3  2017/12/22  10:51:13    25.00    24.75    24.56    25.44       121   \n",
       "4  2017/12/22  10:51:44    25.00    24.75    24.56    25.44       121   \n",
       "\n",
       "   S2_Light  S3_Light  S4_Light  S1_Sound  S2_Sound  S3_Sound  S4_Sound  \\\n",
       "0        34        53        40      0.08      0.19      0.06      0.06   \n",
       "1        33        53        40      0.93      0.05      0.06      0.06   \n",
       "2        34        53        40      0.43      0.11      0.08      0.06   \n",
       "3        34        53        40      0.41      0.10      0.10      0.09   \n",
       "4        34        54        40      0.18      0.06      0.06      0.06   \n",
       "\n",
       "   S5_CO2  S5_CO2_Slope  S6_PIR  S7_PIR  Room_Occupancy_Count  \n",
       "0     390      0.769231       0       0                     1  \n",
       "1     390      0.646154       0       0                     1  \n",
       "2     390      0.519231       0       0                     1  \n",
       "3     390      0.388462       0       0                     1  \n",
       "4     390      0.253846       0       0                     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading and displaying the dataset\n",
    "data = pd.read_csv('C:/Users/josep/repos/Wallaroo_Tutorials/room_occupancy/Occupancy_Estimation.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1_Temp</th>\n",
       "      <th>S2_Temp</th>\n",
       "      <th>S3_Temp</th>\n",
       "      <th>S4_Temp</th>\n",
       "      <th>S1_Light</th>\n",
       "      <th>S2_Light</th>\n",
       "      <th>S3_Light</th>\n",
       "      <th>S4_Light</th>\n",
       "      <th>S1_Sound</th>\n",
       "      <th>S2_Sound</th>\n",
       "      <th>S3_Sound</th>\n",
       "      <th>S4_Sound</th>\n",
       "      <th>S5_CO2</th>\n",
       "      <th>S5_CO2_Slope</th>\n",
       "      <th>S6_PIR</th>\n",
       "      <th>S7_PIR</th>\n",
       "      <th>Room_Occupancy_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Room_Occupancy_Count</th>\n",
       "      <td>0.700868</td>\n",
       "      <td>0.671263</td>\n",
       "      <td>0.652047</td>\n",
       "      <td>0.526509</td>\n",
       "      <td>0.849058</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.793081</td>\n",
       "      <td>0.355715</td>\n",
       "      <td>0.573748</td>\n",
       "      <td>0.557853</td>\n",
       "      <td>0.531685</td>\n",
       "      <td>0.460287</td>\n",
       "      <td>0.660144</td>\n",
       "      <td>0.601105</td>\n",
       "      <td>0.633133</td>\n",
       "      <td>0.695138</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       S1_Temp   S2_Temp   S3_Temp   S4_Temp  S1_Light  \\\n",
       "Room_Occupancy_Count  0.700868  0.671263  0.652047  0.526509  0.849058   \n",
       "\n",
       "                      S2_Light  S3_Light  S4_Light  S1_Sound  S2_Sound  \\\n",
       "Room_Occupancy_Count  0.788764  0.793081  0.355715  0.573748  0.557853   \n",
       "\n",
       "                      S3_Sound  S4_Sound    S5_CO2  S5_CO2_Slope    S6_PIR  \\\n",
       "Room_Occupancy_Count  0.531685  0.460287  0.660144      0.601105  0.633133   \n",
       "\n",
       "                        S7_PIR  Room_Occupancy_Count  \n",
       "Room_Occupancy_Count  0.695138                   1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displays the correlations between each and every variable\n",
    "# occupancy_features = [\"S1_Temp\", \"S1_Light\", \"S1_Sound\", \"S5_CO2\", \"Room_Occupancy_Count\"]\n",
    "# data[occupancy_features].corr()\n",
    "correlations = data.corr()\n",
    "correlations[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling our Independent (x) and Dependent (y) Variables from the DataFrame <a class=\"anchor\" id=\"variable\"></a>\n",
    "Next we are going to access the Independent variable `S1_Temp`, `S1_Light`, `S1_Sound`, `S5_CO2` to be stored in X variable and Dependent variable `Room_Occupancy_Count` to be stored Y variable  \n",
    "The `values` function accesses the values in the dataset at the index of the given variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix of features: \n",
      "[[24.94       24.75       24.56       ...  0.76923077  0.\n",
      "   0.        ]\n",
      " [24.94       24.75       24.56       ...  0.64615385  0.\n",
      "   0.        ]\n",
      " [25.         24.75       24.5        ...  0.51923077  0.\n",
      "   0.        ]\n",
      " ...\n",
      " [25.13       25.06       24.69       ...  0.          0.\n",
      "   0.        ]\n",
      " [25.13       25.06       24.69       ...  0.          0.\n",
      "   0.        ]\n",
      " [25.13       25.06       24.69       ...  0.          0.\n",
      "   0.        ]]\n",
      "\n",
      "The dependent variable matrix: \n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Matrix of features x and prints data x\n",
    "X = data.iloc[:, 2:-1].values\n",
    "print(\"The matrix of features: \\n{}\\n\".format(X))\n",
    "\n",
    "Y = data['Room_Occupancy_Count'].values\n",
    "print(\"The dependent variable matrix: \\n{}\".format(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Data Set into Testing and Training Subsets <a class=\"anchor\" id=\"test_train\"></a>\n",
    "Next we use the `train_test_split()` method in the sklearn library to split the data into test and train sets. \n",
    "\n",
    "Then we use train_test_split which sets test/train data into x and y. \n",
    "\n",
    "Create test and train datasets with 0.2 (20%) of the dataset being test data.\n",
    "\n",
    "The `random_state` decides which indices of data to pull from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The train_test_split gives test/train data to x and y\n",
    "# Create test and train datasets with 0.2 (20%) of the dataset being test data\n",
    "# The random_state decides which indices of data to pull from\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Linear Regression Model using Sklearn and Fitting our Training Data to the Model <a class=\"anchor\" id=\"make_model\"></a>\n",
    "Now using `LinearRegression()` method we create a linear regression object which we call `regr`.\n",
    "\n",
    "Then we take `.fit(x_train, y_train)` method uses x and y train data as parameters to see how well it fits the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Creating the linear regression object\n",
    "occupancy_model = LinearRegression()\n",
    "\n",
    "# The regr.fit() measures how well the x and y train data fit the model\n",
    "occupancy_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x4', 'x12', 'x13', 'x15'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfsForw = SFS(occupancy_model, n_features_to_select = 4, direction = \"forward\")\n",
    "\n",
    "sfsForw.fit(x_train, y_train)\n",
    "\n",
    "sfsForw.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x2', 'x3', 'x4', 'x13'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfsBack = SFS(occupancy_model, n_features_to_select = 4, direction = \"backward\")\n",
    "\n",
    "sfsBack.fit(x_train, y_train)\n",
    "\n",
    "sfsBack.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the Room Occupancy from our Independent Variable Test Set <a class=\"anchor\" id=\"predict\"></a>\n",
    "In this step we take in the independent variable test set for a the parameter in the `predict()` method in order to predict the outcome for the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regr.predict() creates a prediction based on the x test data\n",
    "y_pred = occupancy_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Metrics to Analyze the Prediction <a class=\"anchor\" id=\"metrics\"></a>\n",
    "In this step we use various functions and methods in order to see how well our linear regression model is predicting our data. \n",
    "\n",
    "The  `coef_` function tells us the **correlation coefficient**, which shows in what way our variables correlate with each other. \n",
    "\n",
    "Next up we have the `mean_squared_error()` method, which shows us the distance from the estimated values and the true values; The best possible score would be 0.\n",
    "\n",
    "Lastly there's the `r2_score()` method which is responsible for displaying how well our data fits the current model, with an R^2 score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [0.16267571 0.01127446 0.22855009 0.00083072]\n",
      "Root mean squared error: 0.47\n",
      "Coefficient of determination: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Prints the coefficients\n",
    "print(\"Coefficients: \\n\", occupancy_model.coef_)\n",
    "\n",
    "# Prints the mean squared error\n",
    "print(\"Root mean squared error: %.2f\" % mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# Prints the coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Linear Regression <a class=\"anchor\" id=\"plot\"></a>\n",
    "Using `plt` in **matplotlib** library we can print out the different aspects of our linear regression graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-86f3b0962f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The plt.scatter() plots the x and y test points in the linear regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"black\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The plt.plot() creates the line of best fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2805\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2806\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 2807\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   2808\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4321\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    }
   ],
   "source": [
    "# The plt.scatter() plots the x and y test points in the linear regression model\n",
    "plt.scatter(x_test, y_test, color=\"black\")\n",
    "\n",
    "# The plt.plot() creates the line of best fit\n",
    "plt.plot(x_test, y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "# Sets the x-axis, y-axis, and title of the model\n",
    "plt.xlabel('S1_Temp, S1_Light, S1_Sound, and S5_CO2')\n",
    "plt.ylabel('Room Occupancy')\n",
    "plt.title('Room Occupancy VS S1_Temp, S1_Light, S1_Sound, and S5_CO2 Sensors')\n",
    "\n",
    "# The plt.show() displays the model\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the Model into Wallaroo <a class=\"anchor\" id=\"wallaroo\"></a>\n",
    "The model that was created will now be deployed into the Wallaroo platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the Sklearn Model into Onnx for use on the Wallaroo Platform <a class=\"anchor\" id=\"onnx\"></a>\n",
    "For the next step refer to [sklearn-regression-to-onnx tutorial](https://docs.wallaroo.ai/wallaroo-tutorials/conversion-tutorials/sklearn-regression-to-onnx/) in the wallaroo documentation for how to convert file to onnx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to load the sk-learn model\n",
    "import pickle\n",
    "\n",
    "# Used for the conversion process\n",
    "import onnx, skl2onnx, onnxmltools\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.data_types import DoubleTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model_to_onnx converts the model to onnx to be upload to Wallaroo Platfrom\n",
    "# For more detailed steps refer to \"model_conversion\"\n",
    "def model_to_onnx(model, cols, *, input_type='Double'):\n",
    "    input_type_lower=input_type.lower()\n",
    "    # How to manage float values\n",
    "    if input_type=='Double':\n",
    "        tensor_type=DoubleTensorType\n",
    "    elif input_type=='Float':\n",
    "        tensor_type=FloatTensorType\n",
    "    else:\n",
    "        raise ValueError(\"bad input type\")\n",
    "    tensor_size=cols\n",
    "    initial_type=[(f'{input_type_lower}_input', tensor_type([None, tensor_size]))]\n",
    "    onnx_model=onnxmltools.convert_sklearn(model,initial_types=initial_type)\n",
    "    return onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model_to_onnx() takes the pickle file and converts it to onnx\n",
    "onnx_model_converted = model_to_onnx(occupancy_model, 4)\n",
    "\n",
    "# The onnx.save_model() saves the converted model into a file\n",
    "onnx.save_model(onnx_model_converted, \"occupancy_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing into Wallaroo <a class=\"anchor\" id=\"implement\"></a>\n",
    "Reference the [Wallaroo 101 Tutorial](https://docs.wallaroo.ai/wallaroo-101/) for how to access the wallaroo platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for the use of Wallaroo\n",
    "import wallaroo\n",
    "\n",
    "# The wallaroo.Client() allows the file to access wallaroo platform\n",
    "wl = wallaroo.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the name for workspace, pipeline, and model\n",
    "workspace_name = 'multi variable'\n",
    "pipeline_name = 'occupancymultivarpipeline'\n",
    "model_name = 'occupancymultivarmodel'\n",
    "\n",
    "# Created to fetch the model\n",
    "model_file_name = 'occupancy_model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get_workspace() gets/create the workspace when needed\n",
    "# For more detailed steps refer to \"wallaroo-101\"\n",
    "def get_workspace(name):\n",
    "    workspace = None\n",
    "    for ws in wl.list_workspaces():\n",
    "        if ws.name() == name:\n",
    "            workspace= ws\n",
    "    if(workspace == None):\n",
    "        workspace = wl.create_workspace(name)\n",
    "    return workspace\n",
    "\n",
    "# The get_pipeline() gets/create the pipeline when needed\n",
    "# For more detailed steps refer to \"wallaroo-101\"\n",
    "def get_pipeline(name):\n",
    "    try:\n",
    "        pipeline = wl.pipelines_by_name(pipeline_name)[0]\n",
    "    except EntityNotFoundError:\n",
    "        pipeline = wl.build_pipeline(pipeline_name)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls function to create workspace\n",
    "workspace = get_workspace(workspace_name)\n",
    "\n",
    "# The wl.set_current_workspace() sets the workspace to currently being worked on\n",
    "ws = wl.set_current_workspace(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thw wl.list_workspaces() prints the lists of the workspaces\n",
    "wl.list_workspaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl.set_current_workspace(workspace)\n",
    "#gw = wl.get_current_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Pipeline and Uploading the Model <a class=\"anchor\" id=\"pipeline\"></a>\n",
    "In this step we are using `build_pipeline()`. Here we create the pipeline by giving the method a string. We defined `pipeline_name` earlier.\n",
    "\n",
    "To upload the model we use `upload_model()`. Here we need give a string, and a file. Both we defined earlier in the tutorial.\n",
    "\n",
    "Lastly, we add the model as a step to the pipeline using `add_model_step()`. All we have to give here is give the function our model we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The wl.build_pipeline() creates the pipeline\n",
    "occupancy_pipeline = wl.build_pipeline(pipeline_name)\n",
    "\n",
    "# The occuupancy_pipeline.add_model_step() adds the model to pipeline to be deployed\n",
    "occupancy_pipeline = occupancy_pipeline.add_model_step(occupancy_model_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Validation to the model  <a class=\"anchor\" id=\"validation\"></a>\n",
    "The `add_validation()` takes in two parameters.  \n",
    "\n",
    "**add_validation**(**string** name, **bool** condition)  \n",
    "\n",
    "**Parameters:**\n",
    "* **Name**: This must be lower-case. It is an arbitrary name used to name the condition.  \n",
    "* **Condition**: This describes the condition you want to **NOT** mark as an anomaly. First, give the output values and if greater/less/equal to a chosen value.  \n",
    "\n",
    "The validation step must be implemented before deploying the pipeline and before adding a post process step (In the current version of Wallaroo, this is a work-around to a known issue).  \n",
    "\n",
    "In our code, we name our validation as `no_negative_people`. The condition takes in our `occupancy_model` outputs and compares it to the `float(0)`. This needs to be a float because `occupancy_model` will output floats. So we are only allowing the values greater than or equal to 0.0 to not be marked as an anomaly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_pipeline = occupancy_pipeline.add_validation(\n",
    "                                        'no_negative_people',\n",
    "                                        occupancy_model.outputs[0][0] >= float(0)\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Post-Process <a class=\"anchor\" id=\"postprocess\"></a>\n",
    "The post process step formats the data. We are able to implemennt whatever formatting rules we want.\n",
    "\n",
    "In this tutorial, since we cannot have a fraction of a person, we implement rounding.\n",
    "\n",
    "Here we are uploading another \"model\" to our pipeline.\n",
    "\n",
    "First, we must take our `postproccess.py` file and upload it to Wallaroo using `wl.upload_model()`. We are naming this model `postprocess`. We are also sending our `postprocess.py` file. This time we must also configure it as a python file. \n",
    "\n",
    "We then need to add the model to our pipeline using `add_model_step()` as we did before with our model.\n",
    "Except this time, we upload `module_post`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_post = wl.upload_model(\"postprocess\", \"./postprocess.py\").configure('python')\n",
    "\n",
    "occupancy_pipeline = occupancy_pipeline.add_model_step(module_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Wallaroo's Monitoring Capabilities to Analyze the Model <a class=\"anchor\" id=\"analyze\"></a>\n",
    "Since the model is now deployed we will continue to monitor it and analyze it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploying the Model <a class=\"anchor\" id=\"deploy\"></a>\n",
    "We are close to the final step now. Here we utilize Wallaroo's amazing cluster to run our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The occupancy_pipeline.deploy() activating the pipeline\n",
    "occupancy_pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the deployment <a class=\"anchor\" id=\"check\"></a>\n",
    "This can be a usefull line of code, to ensure that the pipeline is running succesfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The occupancy_pipeline.status() displays the status of the pipeline\n",
    "occupancy_pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making an Inference <a class=\"anchor\" id=\"inference\"></a>\n",
    "\n",
    "Finally, we get to utilize all of our work and put it into production.\n",
    "\n",
    "In this first box, we are just implementing a function that will format our data into a dictionary format. This format is needed in order to properly run inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Single Datums <a class=\"anchor\" id=\"datums\"></a>\n",
    "\n",
    "Here we just need to grab the data from our .csv that we want to infer upon.\n",
    "\n",
    "In our setting, we will pretend that our sensors are sending our pipeline a single datum at a time. In our scenrio, we will send a good datum (something that won't trigger a validation error) and we will also send a bad datum (something that will trigger a validation error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tensor': [[24.94, 121.0, 0.08, 390.0]]}\n",
      "{'tensor': [[24.94, -121.0, 0.08, 390.0]]}\n"
     ]
    }
   ],
   "source": [
    "# Needed for the infrences\n",
    "import json\n",
    "from wallaroo.object import EntityNotFoundError\n",
    "\n",
    "# The pandas_to_dict() converts the values into dictionary for infrences\n",
    "def pandas_to_dict(df):\n",
    "    input_dict = {\n",
    "    'tensor': df.to_numpy().tolist()\n",
    "    }\n",
    "    return input_dict\n",
    "\n",
    "good_data = pandas_to_dict(pd.read_csv('Good_Datum.csv').iloc[:,[2, 6, 10, 14]])\n",
    "bad_data = pandas_to_dict(pd.read_csv('Bad_Datum.csv').iloc[:10,[2, 6, 10, 14]])\n",
    "\n",
    "print(good_data)\n",
    "print(bad_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the inference <a class=\"anchor\" id=\"makeinference\"></a>\n",
    "\n",
    "`occupancy_pipeline.infer()`  \n",
    "This method takes our input data that we pulled from our data, and creates the inference. \n",
    "\n",
    "The result shows the data we placed in, the outputs from the inference, and lastly, our post process step that rounds the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The occupancy_pipeline.infer() creates a result based on data given\n",
    "# result = occupancy_pipeline.infer(input_dict)\n",
    "# result\n",
    "\n",
    "# The occupancy_pipeline.infer() creates a result based on data given\n",
    "good_result = occupancy_pipeline.infer(good_data)\n",
    "bad_result = occupancy_pipeline.infer(bad_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the Inference <a class=\"anchor\" id=\"interpret\"></a>\n",
    "\n",
    "By printing `good_result` and `bad_result` we can see the actual output. On the first line `InferenceResult` it shows `check_failures`.\n",
    "\n",
    "In our `good_result`, we see that there are no failures. However in `bad_result`, we see that the validation step found a failure.\n",
    "\n",
    "This result also shows the information that was run. You can find the following information:  \n",
    "`model_name` - name of the model.  \n",
    "`orginal_data` - the data we placed into the inference.  \n",
    "`outputs` - the raw output.  \n",
    "`prediction` - the output after it has been processed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_result)\n",
    "print(\"-\"*100)\n",
    "print(bad_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Results <a class=\"anchor\" id=\"results\"></a>\n",
    "\n",
    "`result[0].data()[0].tolist()`  \n",
    "This will show the prediction of our inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results in a nicely formatted way.\n",
    "print(\"Finalized Data\\n--------------------\")\n",
    "print(\"Good Result :\",good_result[0].data()[0].tolist())\n",
    "print(\"Bad Result :\",bad_result[0].data()[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undeploy the pipeline <a class=\"anchor\" id=\"undeploy\"></a>\n",
    "\n",
    "This part is crucial, you do not want take up more resources than you meant to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The occupancy_pipeline.undeploy() deactivates the pipeline\n",
    "occupancy_pipeline.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs <a class=\"anchor\" id=\"logs\"></a>\n",
    "\n",
    "`.logs()`\n",
    "\n",
    "Lastly, the pipeline logs can be deployed, even after the pipeline is undeployed.\n",
    "\n",
    "We can see both good and bad datums being represented in the logs.  \n",
    "A log without an anomaly will be shown in white.  \n",
    "A log with an anomaly will be shown in red. It will also list how many anomalies were found in the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = occupancy_pipeline.logs()\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f77ad3bbdc25706dbd2075c576f7f010f16198040aba21ec1041af432b4ca7ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
