{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Curve Pipeline\n",
    "\n",
    "This worksheet demonstrates a Wallaroo pipeline with data preprocessing, a model, and data postprocessing.\n",
    "\n",
    "The model is a \"demand curve\" that predicts the expected number of units of a product that will be sold to a customer as a function of unit price and facts about the customer. Such models can be used for price optimization or sales volume forecasting.\n",
    "\n",
    "Data preprocessing is required to create the features used by the model. Simple postprocessing prevents nonsensical estimates (e.g. negative units sold).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wallaroo\n",
    "import pandas\n",
    "import numpy\n",
    "import conversion\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up the wallaroo client, and upload the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WALLAROO_SDK_CREDENTIALS\"] = 'creds.json'\n",
    "wl = wallaroo.Client(auth_type=\"user_password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_workspace = wl.create_workspace(\"demandcurve-workspace\")\n",
    "_ = wl.set_current_workspace(new_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure, let's list our current workspace.  If everything is going right, it will show us we're in the `demandcurve-workspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'demandcurve-workspace', 'id': 2, 'archived': False, 'created_by': '7dbb3754-4c14-4730-8b77-33caeea7a2a0', 'created_at': '2022-03-28T16:28:21.625896+00:00', 'models': [], 'pipelines': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.get_current_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the models to Wallaroo:\n",
    "\n",
    "* `demand_curve_v1.onnx`: Our demand_curve model.  We'll store the upload configuration into `demand_curve_model`.\n",
    "* `preprocess`:  Takes the data and prepares it for the demand curve model.  We'll store the upload configuration into `module_pre`.\n",
    "* `postprocess`:  Takes the results from our demand curve model and prepares it for our display.  We'll store the upload configuration into `module_post`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to wallaroo\n",
    "demand_curve_model = wl.upload_model('demandcurve', \"./demand_curve_v1.onnx\").configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the preprocess module\n",
    "module_pre = wl.upload_model(\"preprocess\", \"./preprocess.py\").configure('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the postprocess module\n",
    "module_post = wl.upload_model(\"postprocess\", \"./postprocess.py\").configure('python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our models uploaded, we're gong to create our own pipeline and give it three steps:\n",
    "\n",
    "* First, start with the preprocess module we called `module_pre` to prepare the data.\n",
    "* Second, we apply the data to our `demand_curve_model`.\n",
    "* And finally, we prepare our data for output with the `module_post`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make a pipeline\n",
    "demandcurve_pipeline = (wl.build_pipeline(\"demand-curve-pipeline\")\n",
    "                        .add_model_step(module_pre)\n",
    "                        .add_model_step(demand_curve_model)\n",
    "                        .add_model_step(module_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that - let's deploy our model pipeline.  This usually takes about 45 seconds for the deployment to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment - this will take up to 45s ........ ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'demand-curve-pipeline', 'create_time': datetime.datetime(2022, 3, 28, 16, 28, 22, 313553, tzinfo=tzutc()), 'definition': \"[{'ModelInference': {'models': [{'name': 'preprocess', 'version': 'b1f51290-ac47-4289-8a55-310507d52af5', 'sha': 'c328e2d5bf0adeb96f37687ab4da32cecf5f2cc789fa3a427ec0dbd2c3b8b663'}]}}, {'ModelInference': {'models': [{'name': 'demandcurve', 'version': '9cd1fcae-1fa1-4e12-8e67-d4a67f240a46', 'sha': '2820b42c9e778ae259918315f25afc8685ecab9967bad0a3d241e6191b414a0d'}]}}, {'ModelInference': {'models': [{'name': 'postprocess', 'version': '06e79dfe-623e-482e-95f6-bd6fa1b26264', 'sha': '4bd3109602e999a3a5013893cd2eff1a434fd9f06d6e3e681724232db6fdd40d'}]}}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demandcurve_pipeline.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the status of our pipeline to make sure everything was set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Running',\n",
       " 'details': None,\n",
       " 'engines': [{'ip': '10.12.1.227',\n",
       "   'name': 'engine-7cbf9b8d6d-xs64b',\n",
       "   'status': 'Running',\n",
       "   'reason': None,\n",
       "   'pipeline_statuses': {'pipelines': [{'id': 'demand-curve-pipeline',\n",
       "      'status': 'Running'}]},\n",
       "   'model_statuses': {'models': [{'name': 'demandcurve',\n",
       "      'version': '9cd1fcae-1fa1-4e12-8e67-d4a67f240a46',\n",
       "      'sha': '2820b42c9e778ae259918315f25afc8685ecab9967bad0a3d241e6191b414a0d',\n",
       "      'status': 'Running'},\n",
       "     {'name': 'preprocess',\n",
       "      'version': 'b1f51290-ac47-4289-8a55-310507d52af5',\n",
       "      'sha': 'c328e2d5bf0adeb96f37687ab4da32cecf5f2cc789fa3a427ec0dbd2c3b8b663',\n",
       "      'status': 'Running'},\n",
       "     {'name': 'postprocess',\n",
       "      'version': '06e79dfe-623e-482e-95f6-bd6fa1b26264',\n",
       "      'sha': '4bd3109602e999a3a5013893cd2eff1a434fd9f06d6e3e681724232db6fdd40d',\n",
       "      'status': 'Running'}]}}],\n",
       " 'engine_lbs': [{'ip': '10.12.1.226',\n",
       "   'name': 'engine-lb-85846c64f8-6l9rr',\n",
       "   'status': 'Running',\n",
       "   'reason': None}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demandcurve_pipeline.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ready.  Let's feed our pipeline some data.  We have some information prepared with the `daily_purchasses.csv` spreadsheet.  We'll start with just one row to make sure that everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for inference response - this will take up to 45s .. ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[InferenceResult({'check_failures': [],\n",
       "  'elapsed': 479657,\n",
       "  'model_name': 'postprocess',\n",
       "  'model_version': '06e79dfe-623e-482e-95f6-bd6fa1b26264',\n",
       "  'original_data': {'colnames': ['Date',\n",
       "                                 'cust_known',\n",
       "                                 'StockCode',\n",
       "                                 'UnitPrice',\n",
       "                                 'UnitsSold'],\n",
       "                    'query': [['2010-12-01', False, '21928', 4.21, 1]]},\n",
       "  'outputs': [{'Json': {'data': [{'original': {'outputs': [{'Double': {'data': [6.68025518653071],\n",
       "                                                                       'dim': [1,\n",
       "                                                                               1],\n",
       "                                                                       'v': 1}}]},\n",
       "                                  'prediction': [6.68025518653071]}],\n",
       "                        'dim': [1],\n",
       "                        'v': 1}}],\n",
       "  'pipeline_name': 'demand-curve-pipeline',\n",
       "  'time': 1648484916799})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in some purchase data\n",
    "purchases = pandas.read_csv('daily_purchases.csv')\n",
    "\n",
    "# start with a one-row data frame for testing\n",
    "subsamp_raw = purchases.iloc[0:1,: ]\n",
    "subsamp_raw\n",
    "\n",
    "# create the input dictionary from the original one-line dataframe\n",
    "input_dict = conversion.pandas_to_dict(subsamp_raw)\n",
    "\n",
    "result = demandcurve_pipeline.infer(input_dict)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([6.68025519])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Timestamp</th>\n",
       "                <th>Output</th>\n",
       "                <th>Input</th>\n",
       "                <th>Anomalies</th>\n",
       "            </tr>\n",
       "            \n",
       "        <tr style=\"\">\n",
       "            <td>2022-28-Mar 16:25:09</td>\n",
       "            <td>[array([6.68025519])]</td>\n",
       "            <td>{'colnames': ['Date', 'cust_known', 'StockCode', 'UnitPrice', 'UnitsSold'], 'query': [['2010-12-01', False, '21928', 4.21, 1]]}</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        \n",
       "\n",
       "        <tr style=\"\">\n",
       "            <td>2022-28-Mar 16:25:20</td>\n",
       "            <td>[array([ 6.77154593, 49.73419364,  6.77154593,  0.        , 49.73419364,\n",
       "        9.11087115,  6.77154593,  6.77154593,  9.11087115, 33.12532316])]</td>\n",
       "            <td>{'colnames': ['Date', 'cust_known', 'StockCode', 'UnitPrice', 'UnitsSold'], 'query': [['2011-02-01', False, '85099F', 4.13, 1], ['2011-09-22', True, '85099F', 1.79, 20], ['2011-07-13', False, '22386', 4.13, 7], ['2011-10-10', True, '21931', 4.13, 1], ['2011-06-10', True, '22386', 1.79, 100], ['2011-11-30', False, '85099B', 2.08, 13], ['2011-09-23', False, '23343', 4.13, 1], ['2011-04-04', False, '21928', 4.13, 1], ['2011-06-27', False, '23199', 2.08, 9], ['2011-06-20', True, '22411', 2.08, 20]]}</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        \n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "[<wallaroo.logs.LogEntry at 0x7f92a8daa460>,\n",
       " <wallaroo.logs.LogEntry at 0x7f92a8daa5e0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demandcurve_pipeline.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial test went perfectly.  Now let's throw some more data into our pipeline.  We'll draw 10 random rows from our spreadsheet and perform an inference from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do 10 rows at once (drawn randomly)\n",
    "ix = numpy.random.choice(purchases.shape[0], size=10, replace=False)\n",
    "output = demandcurve_pipeline.infer(conversion.pandas_to_dict(purchases.iloc[ix,: ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([33.12532316,  6.77154593,  6.77154593, 40.57067889, 40.57067889,\n",
       "         6.77154593, 33.12532316,  6.77154593,  9.11087115, 40.57067889])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <th>Timestamp</th>\n",
       "                <th>Output</th>\n",
       "                <th>Input</th>\n",
       "                <th>Anomalies</th>\n",
       "            </tr>\n",
       "            \n",
       "        <tr style=\"\">\n",
       "            <td>2022-28-Mar 16:25:09</td>\n",
       "            <td>[array([6.68025519])]</td>\n",
       "            <td>{'colnames': ['Date', 'cust_known', 'StockCode', 'UnitPrice', 'UnitsSold'], 'query': [['2010-12-01', False, '21928', 4.21, 1]]}</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        \n",
       "\n",
       "        <tr style=\"\">\n",
       "            <td>2022-28-Mar 16:25:20</td>\n",
       "            <td>[array([ 6.77154593, 49.73419364,  6.77154593,  0.        , 49.73419364,\n",
       "        9.11087115,  6.77154593,  6.77154593,  9.11087115, 33.12532316])]</td>\n",
       "            <td>{'colnames': ['Date', 'cust_known', 'StockCode', 'UnitPrice', 'UnitsSold'], 'query': [['2011-02-01', False, '85099F', 4.13, 1], ['2011-09-22', True, '85099F', 1.79, 20], ['2011-07-13', False, '22386', 4.13, 7], ['2011-10-10', True, '21931', 4.13, 1], ['2011-06-10', True, '22386', 1.79, 100], ['2011-11-30', False, '85099B', 2.08, 13], ['2011-09-23', False, '23343', 4.13, 1], ['2011-04-04', False, '21928', 4.13, 1], ['2011-06-27', False, '23199', 2.08, 9], ['2011-06-20', True, '22411', 2.08, 20]]}</td>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "        \n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "[<wallaroo.logs.LogEntry at 0x7f92311e7d60>,\n",
       " <wallaroo.logs.LogEntry at 0x7f92311e7eb0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demandcurve_pipeline.logs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
